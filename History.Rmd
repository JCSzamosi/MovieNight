Movie Nights through History
===========================

Setup
------

```{r Setup, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(message=FALSE, warning=FALSE)
library(tidyverse)
library(lubridate)
theme_set(theme_bw())
setwd('~/Projects/MovieNight/')
```

### Import Data

The script that pulls all previous weeks' voting results is [here](./get_old.sh)
and comes courtesy of @gnomon.

I import each file, merge them together into a single data frame, and write it
back to disk.

```{r Import, results = 'hide', eval=FALSE}
weeks = list.files(path = 'old_data', pattern = 'week', full.names = TRUE)
movies = list.files(path = 'old_data', pattern = 'movies', full.names = TRUE)
movie_df = read.csv(movies[1], row.names = 1, header = FALSE)
movie_df
titles = movie_df[[1]]
names(titles) = rownames(movie_df)
titles
weeks[1]
substr(weeks[1], 10, 19)
vote_df = read.csv(weeks[1], check.names = FALSE)
vote_df
vote_df = (vote_df
           %>% gather(TitleLong, Vote, -Timestamp)
           %>% count(TitleLong, Vote, name = 'Count') 
           %>% mutate(Week = substr(weeks[1], 10, 19),
                      Title = titles[TitleLong]))
vote_df

for (week in weeks[2:length(weeks)]){
    movie = gsub('week','movies',week)
    movie_df = read.csv(movie, row.names = 1, header = FALSE)
    titles = movie_df[[1]]
    names(titles) = rownames(movie_df)
    vote_df = rbind(vote_df,
                    (read.csv(week, check.names = FALSE)
                     %>% gather(TitleLong, Vote, -Timestamp)
                     %>% count(TitleLong, Vote, name = 'Count')
                     %>% mutate(Week = substr(week, 10, 19),
                                Title = titles[TitleLong])))
}

head(vote_df)
tail(vote_df)
vote_df = (vote_df
           %>% spread(Vote, Count, fill = 0)
           %>% gather(Vote, Count, starts_with('I')))
head(vote_df)
write.csv(vote_df, file = 'all_weeks.csv', row.names = TRUE)
```

Once the data have been merged, I open them in OpenRefine to clean up any 
instances of the same movie being given slightly different names on different
weeks. The JSON file with the OpenRefine commands is
[here](./open_refine_cleaning.json).

Then I read in the cleaned data:

```{r Cleaned, results='hide'}
all_dat = read.csv('all-weeks-cleaned.csv')
head(all_dat)
all_dat = select(all_dat, -Column)
levels(factor(all_dat$Vote))
all_dat = (all_dat
           %>% mutate(Week = ymd(Week),
                      Vote = factor(Vote, 
                                    labels = c('meh', 'Nope', 'Yes please!')),
                      Vote = factor(Vote, levels = c('Yes please!', 'meh', 'Nope'))))
```

Naive Visualization
-------------------

Without filtering out any themed weeks, holidays, weeks when there was an error
in the poll, etc., here are some plots:

```{r}
cat_totals = (all_dat
              %>% group_by(Week, Vote)
              %>% summarize(Count = sum(Count)))
cat_plt = ggplot(cat_totals, aes(Week, Count, colour = Vote)) +
    geom_line() +
    scale_colour_brewer(palette = 'Dark2') +
    ylim(0, 90) +
    ylab('Number of Votes') +
    ggtitle('Total votes in each category over time')
cat_plt
    
tots = (cat_totals
        %>% group_by(Week)
    %>% summarize(Count = sum(Count)/8))
tot_plt = ggplot(tots, aes(Week, Count)) +
    geom_line() +
    ylim(0,25) +
    ylab('Number of Voters') +
    ggtitle('Number of people who voted over time')
tot_plt
```

These are both pretty noisy. I'm seeing that the number of negative votes was 
lower in the beginning, climbed over the first few months that we used this 
system, and has stabilized pretty well. The number of voters each week is harder
to make sense of through the noise. Some moving-window averaging will probably
help clarify that.

```{r}
cat_prop = (cat_totals
           %>% group_by(Week)
           %>% mutate(CountProp = Count/sum(Count),
                      Total = sum(Count)/8)
           %>% ungroup())
head(cat_prop)

cat_prop_plt = ggplot(cat_prop, aes(Total, CountProp, colour = Vote)) +
    geom_point() +
    geom_smooth(method = 'lm') +
    scale_colour_brewer(palette = 'Dark2') +
    ggtitle('Proportion of votes in each category vs. number of voters')
cat_prop_plt
```

Typically, the 'meh' category gets the most votes, while the negative category
gets the fewest. There appears to be a negative relationship between the number 
of people voting and the number of 'meh' votes cast. A positive relationship 
between number of voters and 'yes' votes is apparent, but weaker. 
I have not done a statistics.

Most Frequent Candidates
-------------------------

Of the movies that have not won, these have been on the list the most 
frequently.

```{r}
# head(all_dat)

winners = read.csv('winners.csv')
# head(winners)

freqs = (all_dat
  %>% filter(!(Title %in% winners$Winner))
  %>% count(Title)
  %>% mutate(Count = n/3)
  %>% arrange(desc(n), desc(Title))
  %>% select(-n))
freqs %>% filter(Count >= 5)
```

I have also manually curated a list of the movies most in keeping with our
80's/90's computer nerd roots:

* batteries not included
* war games
* burn after reading
* robocop
* spy kids
* turbo kid
* terminator 2
* the net
* tracer

Runners Up
----------

```{r}
get_second = function(v){
  r = rank(-1*v)
  return(which(r == 2))
}

seconds = (all_dat
 %>% filter(SpecialWeek == '')
 %>% spread(Vote,Count)
 %>% mutate(Score = `Yes please!` - Nope)
 %>% group_by(Week)
 %>% summarize(Second = Title[get_second(Score)])
 %>% filter(!(Second %in% winners$Winner)))

(seconds
  %>% count(Second)
  %>% arrange(desc(n)))
```

Once previous winners are excluded, no movie came in second more than once

Here are the movies that came in second, sorted by how frequently they
occurred in lists at all.

```{r}
sec_freq = left_join(seconds, freqs, by = c('Second' = 'Title'))
sec_freq %>% arrange(desc(Count), desc(Second))
```


To Do
-----

* Further clean the data to tease out theme/holiday/error weeks vs. everything
else
* Multinomial regression of proportion votes/cat vs. # voters
* Suggestions are welcome via the [issues 
tab](https://github.com/JCSzamosi/MovieNight/issues), but may be ignored.